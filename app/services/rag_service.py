"""
RAG (Retrieval-Augmented Generation) Service
LangChain + ChromaDB + OpenAIë¥¼ ì‚¬ìš©í•œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•ˆë‚´ë¬¸ ìƒì„±
"""
import os
from typing import List, Dict, Optional
from pathlib import Path

from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from loguru import logger

from app.config import settings


class RAGService:
    """RAG ê¸°ë°˜ ì•ˆë‚´ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.chroma_db_path = settings.CHROMA_DB_PATH
        self.embeddings = None
        self.vectorstore = None
        self.llm = None
        self.qa_chain = None

        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(self.chroma_db_path).mkdir(parents=True, exist_ok=True)

        self._initialize()


    def _initialize(self):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # 1. Embedding ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
            logger.info("ğŸ“¦ Loading embedding model...")
            self.embeddings = HuggingFaceEmbeddings(
                model_name=settings.EMBEDDING_MODEL,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )

            # 2. ChromaDB ë¡œë“œ ë˜ëŠ” ìƒì„±
            logger.info("ğŸ—„ï¸ Loading vector database...")
            self.vectorstore = Chroma(
                persist_directory=self.chroma_db_path,
                embedding_function=self.embeddings
            )

            # 3. LLM ì´ˆê¸°í™” (OpenAI)
            if settings.OPENAI_API_KEY:
                logger.info("ğŸ¤– Initializing LLM...")
                self.llm = ChatOpenAI(
                    model_name="gpt-3.5-turbo",
                    temperature=0.3,
                    openai_api_key=settings.OPENAI_API_KEY
                )

                # 4. QA Chain ìƒì„±
                self._create_qa_chain()
            else:
                logger.warning("âš ï¸ OpenAI API key not set. RAG will use simple retrieval only.")

            logger.info("âœ… RAG service initialized successfully!")

        except Exception as e:
            logger.error(f"âŒ Error initializing RAG: {e}")


    def _create_qa_chain(self):
        """QA Chain ìƒì„± (ë…¸ì¸ ì¹œí™”ì  ë°°ë¦¬ì–´í”„ë¦¬ ì•ˆë‚´ í”„ë¡¬í”„íŠ¸)"""
        prompt_template = """
ë‹¹ì‹ ì€ êµí†µì•½ì(ë…¸ì¸, íœ ì²´ì–´ ì‚¬ìš©ì)ë¥¼ ìœ„í•œ ì¹œì ˆí•œ ì§€í•˜ì²  ë°°ë¦¬ì–´í”„ë¦¬ ì•ˆë‚´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ ê·œì¹™:
1. ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: ~í•˜ì„¸ìš”, ~ì…ë‹ˆë‹¤)
2. 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”
3. êµ¬ì²´ì ì¸ ìœ„ì¹˜ì™€ ë°©í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš” (ì˜ˆ: "ì¶œêµ¬ ì™¼ìª½ 10m", "ì•ìª½ìœ¼ë¡œ ì§ì§„")
4. ì—˜ë¦¬ë² ì´í„° ê´€ë ¨ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”
5. ê²½ì‚¬ë¡œ, ê³„ë‹¨ ë“± ì´ë™ì— ì£¼ì˜í•  ì ì„ ì•Œë ¤ì£¼ì„¸ìš”
6. ìˆ«ì(ì¸µìˆ˜, ê±°ë¦¬, ì‹œê°„)ëŠ” ì •í™•í•˜ê²Œ ì•ˆë‚´í•˜ì„¸ìš”
7. ì „ë¬¸ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ê¿”ì£¼ì„¸ìš” (ì˜ˆ: "ì—°ë‹¨ê°„ê²©" â†’ "ìŠ¹ê°•ì¥ê³¼ ì—´ì°¨ ì‚¬ì´ ê°„ê²©")

ë‹µë³€:
"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )

        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": PROMPT}
        )


    def add_documents(self, texts: List[str], metadatas: Optional[List[Dict]] = None):
        """
        ë²¡í„° DBì— ë¬¸ì„œ ì¶”ê°€

        Args:
            texts: ì¶”ê°€í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            metadatas: ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
        """
        try:
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )

            documents = [Document(page_content=text, metadata=meta or {})
                        for text, meta in zip(texts, metadatas or [{}] * len(texts))]

            split_docs = text_splitter.split_documents(documents)

            # ë²¡í„° DBì— ì¶”ê°€
            self.vectorstore.add_documents(split_docs)
            self.vectorstore.persist()

            logger.info(f"âœ… Added {len(split_docs)} document chunks to vector DB")

        except Exception as e:
            logger.error(f"âŒ Error adding documents: {e}")


    def search(self, query: str, k: int = 3) -> List[Dict]:
        """
        ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜

        Returns:
            [{"content": "...", "metadata": {...}}, ...]
        """
        try:
            results = self.vectorstore.similarity_search(query, k=k)

            return [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in results
            ]

        except Exception as e:
            logger.error(f"âŒ Error searching documents: {e}")
            return []


    def generate_guide(
        self,
        question: str,
        db_data: Optional[Dict] = None,
        api_data: Optional[Dict] = None
    ) -> str:
        """
        DB + API + RAGë¥¼ í†µí•©í•˜ì—¬ ì•ˆë‚´ë¬¸ ìƒì„±

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            db_data: DB ì¡°íšŒ ê²°ê³¼
            api_data: Open API ì¡°íšŒ ê²°ê³¼

        Returns:
            ìƒì„±ëœ ì•ˆë‚´ë¬¸
        """
        try:
            # 1. RAG ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            rag_results = self.search(question, k=2)

            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []

            if db_data:
                context_parts.append(f"DB ì •ë³´: {db_data}")

            if api_data:
                context_parts.append(f"ì‹¤ì‹œê°„ ì •ë³´: {api_data}")

            if rag_results:
                for result in rag_results:
                    context_parts.append(f"ì°¸ê³  ìë£Œ: {result['content']}")

            # 3. LLMìœ¼ë¡œ ì•ˆë‚´ë¬¸ ìƒì„±
            if self.qa_chain:
                full_question = f"""
ì»¨í…ìŠ¤íŠ¸:
{chr(10).join(context_parts)}

ì§ˆë¬¸: {question}
"""
                response = self.qa_chain.run(full_question)
                return response.strip()

            else:
                # LLM ì—†ìœ¼ë©´ ê°„ë‹¨í•œ í…œí”Œë¦¿ ì‚¬ìš©
                return self._generate_simple_guide(question, db_data, api_data)

        except Exception as e:
            logger.error(f"âŒ Error generating guide: {e}")
            return self._generate_simple_guide(question, db_data, api_data)


    def _generate_simple_guide(
        self,
        question: str,
        db_data: Optional[Dict] = None,
        api_data: Optional[Dict] = None
    ) -> str:
        """LLM ì—†ì´ ì²´í¬í¬ì¸íŠ¸ íƒ€ì…ë³„ í…œí”Œë¦¿ ê¸°ë°˜ ì•ˆë‚´ë¬¸ ìƒì„±"""

        guide_parts = []

        # ì²´í¬í¬ì¸íŠ¸ íƒ€ì… í™•ì¸
        checkpoint_type = db_data.get('checkpoint_type', '') if db_data else ''
        station_name = db_data.get('station_name', '') if db_data else ''
        need_elevator = db_data.get('need_elevator', False) if db_data else False

        # ì²´í¬í¬ì¸íŠ¸ íƒ€ì…ë³„ ì•ˆë‚´ë¬¸
        if 'ì¶œë°œì§€' in checkpoint_type:
            exit_number = db_data.get('exit_number', '1') if db_data else '1'
            guide_parts.append(f"{station_name} {exit_number}ë²ˆ ì¶œêµ¬ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.")
            if need_elevator:
                guide_parts.append("ì—˜ë¦¬ë² ì´í„°ê°€ ìˆëŠ” ì¶œêµ¬ì…ë‹ˆë‹¤.")

        elif 'ì¶œêµ¬' in checkpoint_type:
            exit_number = db_data.get('exit_number', '1') if db_data else '1'
            if 'ì¶œë°œ' in checkpoint_type:
                guide_parts.append(f"{station_name} {exit_number}ë²ˆ ì¶œêµ¬ì— ë„ì°©í•˜ì…¨ìŠµë‹ˆë‹¤.")
                if need_elevator:
                    guide_parts.append("ì—˜ë¦¬ë² ì´í„°ë¥¼ ì´ìš©í•´ ìŠ¹ê°•ì¥ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
            else:
                guide_parts.append(f"{station_name} {exit_number}ë²ˆ ì¶œêµ¬ì…ë‹ˆë‹¤.")
                if need_elevator:
                    guide_parts.append("ì—˜ë¦¬ë² ì´í„°ë¥¼ ì´ìš©í•´ ì§€ìƒìœ¼ë¡œ ë‚˜ê°€ì„¸ìš”.")

        elif 'ìŠ¹ê°•ì¥' in checkpoint_type:
            if 'ëŒ€ê¸°' in checkpoint_type:
                guide_parts.append(f"{station_name} ìŠ¹ê°•ì¥ì—ì„œ ì—´ì°¨ë¥¼ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
                guide_parts.append("7-8ë²ˆì§¸ ì¹¸ ì•ì—ì„œ ëŒ€ê¸°í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.")
            elif 'ë„ì°©' in checkpoint_type:
                guide_parts.append(f"{station_name}ì— ë„ì°©í•˜ì…¨ìŠµë‹ˆë‹¤!")
                guide_parts.append("ì¶œêµ¬ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
            else:
                guide_parts.append(f"{station_name} ìŠ¹ê°•ì¥ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")

        elif 'ì—´ì°¨' in checkpoint_type or 'íƒ‘ìŠ¹' in checkpoint_type:
            guide_parts.append("ì—´ì°¨ì— íƒ‘ìŠ¹í•˜ì…¨ìŠµë‹ˆë‹¤.")
            guide_parts.append("ë„ì°©ì—­ì—ì„œ í•˜ì°¨í•˜ì„¸ìš”.")

        elif 'ì¶©ì „ì†Œ' in checkpoint_type:
            guide_parts.append(f"{station_name} ì£¼ë³€ íœ ì²´ì–´ ì¶©ì „ì†Œë¥¼ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ì—˜ë¦¬ë² ì´í„° ìƒíƒœ ì •ë³´ ì¶”ê°€
        if api_data:
            elevator_status = api_data.get('elevator_status', {})
            if elevator_status:
                if elevator_status.get('all_working', True):
                    if need_elevator:
                        guide_parts.append("ì—˜ë¦¬ë² ì´í„°ê°€ ì •ìƒ ìš´í–‰ ì¤‘ì…ë‹ˆë‹¤.")
                else:
                    # ì‘ë™í•˜ëŠ” ì—˜ë¦¬ë² ì´í„° ì°¾ì•„ì„œ ì•ˆë‚´
                    elevators = elevator_status.get('elevators', [])
                    working_elevators = [e for e in elevators if e.get('status') == 'ì •ìƒ']

                    if working_elevators:
                        # ì‘ë™í•˜ëŠ” ì—˜ë¦¬ë² ì´í„° ìœ„ì¹˜ ì•ˆë‚´
                        locations = [e.get('location', '') for e in working_elevators if e.get('location')]
                        if locations:
                            guide_parts.append(f"ì¼ë¶€ ì—˜ë¦¬ë² ì´í„°ê°€ ì ê²€ ì¤‘ì…ë‹ˆë‹¤. {locations[0]}ì˜ ì—˜ë¦¬ë² ì´í„°ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.")
                        else:
                            guide_parts.append("ì¼ë¶€ ì—˜ë¦¬ë² ì´í„°ê°€ ì ê²€ ì¤‘ì…ë‹ˆë‹¤. ì •ìƒ ìš´í–‰ ì¤‘ì¸ ì—˜ë¦¬ë² ì´í„°ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.")
                    else:
                        guide_parts.append("ì—˜ë¦¬ë² ì´í„°ê°€ ì ê²€ ì¤‘ì…ë‹ˆë‹¤. ì—­ë¬´ì›ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•˜ì„¸ìš”.")

            # ì—´ì°¨ ë„ì°© ì •ë³´
            train_arrival = api_data.get('train_arrival', [])
            if train_arrival and isinstance(train_arrival, list) and len(train_arrival) > 0:
                first = train_arrival[0]
                if isinstance(first, dict):
                    minutes = first.get('arrival_minutes', 0)
                    if minutes:
                        guide_parts.append(f"ë‹¤ìŒ ì—´ì°¨ê°€ ì•½ {minutes}ë¶„ í›„ ë„ì°©í•©ë‹ˆë‹¤.")

        # ê¸°ë³¸ ë©”ì‹œì§€
        if not guide_parts:
            return "ì•ˆë‚´ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. í‘œì§€íŒì„ ë”°ë¼ ì´ë™í•´ì£¼ì„¸ìš”."

        return " ".join(guide_parts)


    def initialize_subway_knowledge(self):
        """
        ì§€í•˜ì²  ë°°ë¦¬ì–´í”„ë¦¬ ì§€ì‹ ì´ˆê¸°í™”
        - Open APIì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
        - DBì—ì„œ ì—­ë³„ ì •ë³´ ë¡œë”©
        - í•˜ë“œì½”ë”© ì—†ì´ ë™ì ìœ¼ë¡œ ì§€ì‹ êµ¬ì¶•
        """
        logger.info("ğŸ“š Initializing barrier-free subway knowledge from API/DB...")

        from app.services.api_service import GeneralSeoulAPI
        from app.database import SessionLocal

        documents = []
        metadatas = []

        # 1. Open APIì—ì„œ ì—˜ë¦¬ë² ì´í„° ì •ë³´ ìˆ˜ì§‘
        try:
            elevator_data = GeneralSeoulAPI.get_elevator_status()

            # ì—­ë³„ë¡œ ê·¸ë£¹í™”
            stations_elevators = {}
            for elev in elevator_data.get('elevators', []):
                station = elev.get('station_name', '')
                if station not in stations_elevators:
                    stations_elevators[station] = []
                stations_elevators[station].append(elev)

            # ì—­ë³„ ì—˜ë¦¬ë² ì´í„° ì •ë³´ë¥¼ ë¬¸ì„œë¡œ ë³€í™˜
            for station, elevators in stations_elevators.items():
                if not station:
                    continue

                # ì—˜ë¦¬ë² ì´í„° ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
                locations = [e.get('location', '') for e in elevators if e.get('location')]
                floors = [e.get('floors', '') for e in elevators if e.get('floors')]

                if locations:
                    doc = f"{station}ì˜ ì—˜ë¦¬ë² ì´í„°ëŠ” {', '.join(locations[:3])}ì— ìˆìŠµë‹ˆë‹¤."
                    if floors:
                        doc += f" ìš´í–‰ êµ¬ê°„ì€ {floors[0]}ì…ë‹ˆë‹¤."

                    documents.append(doc)
                    metadatas.append({
                        "source": "OpenAPI",
                        "category": "ì—˜ë¦¬ë² ì´í„°",
                        "station": station
                    })

            logger.info(f"âœ… Loaded {len(documents)} elevator documents from Open API")

        except Exception as e:
            logger.error(f"âŒ Failed to load elevator data from API: {e}")

        # 2. Open APIì—ì„œ íœ ì²´ì–´ ì¶©ì „ì†Œ ì •ë³´ ìˆ˜ì§‘
        try:
            charger_data = GeneralSeoulAPI.get_wheelchair_chargers()

            for charger in charger_data:
                station = charger.get('station_name', '')
                location = charger.get('location', '')
                floor = charger.get('floor', '')

                if station and location:
                    doc = f"{station}ì— íœ ì²´ì–´ ì¶©ì „ì†Œê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ì¹˜ëŠ” {location}"
                    if floor:
                        doc += f" ({floor})"
                    doc += "ì…ë‹ˆë‹¤."

                    documents.append(doc)
                    metadatas.append({
                        "source": "OpenAPI",
                        "category": "ì¶©ì „ì†Œ",
                        "station": station
                    })

            logger.info(f"âœ… Loaded charger documents from Open API")

        except Exception as e:
            logger.error(f"âŒ Failed to load charger data from API: {e}")

        # 3. Open APIì—ì„œ íœ ì²´ì–´ ë¦¬í”„íŠ¸ ì •ë³´ ìˆ˜ì§‘
        try:
            lift_data = GeneralSeoulAPI.get_wheelchair_lifts()

            for lift in lift_data:
                station = lift.get('station_name', '')
                location = lift.get('location', '')

                if station and location:
                    doc = f"{station}ì— íœ ì²´ì–´ ë¦¬í”„íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ì¹˜ëŠ” {location}ì…ë‹ˆë‹¤."
                    documents.append(doc)
                    metadatas.append({
                        "source": "OpenAPI",
                        "category": "ë¦¬í”„íŠ¸",
                        "station": station
                    })

            logger.info(f"âœ… Loaded lift documents from Open API")

        except Exception as e:
            logger.error(f"âŒ Failed to load lift data from API: {e}")

        # 4. DBì—ì„œ ì—­ë³„ ì¶œêµ¬/í¸ì˜ì‹œì„¤ ì •ë³´ ë¡œë”©
        try:
            db = SessionLocal()
            from app.models import Station, Exit, StationFacility

            stations = db.query(Station).all()

            for station in stations:
                # ì—˜ë¦¬ë² ì´í„° ìˆëŠ” ì¶œêµ¬ ì •ë³´
                exits_with_elev = db.query(Exit).filter(
                    Exit.station_id == station.station_id,
                    Exit.has_elevator == True
                ).all()

                if exits_with_elev:
                    exit_numbers = [e.exit_number for e in exits_with_elev]
                    doc = f"{station.name}ì—ì„œ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆëŠ” ì¶œêµ¬ëŠ” {', '.join(exit_numbers)}ë²ˆ ì¶œêµ¬ì…ë‹ˆë‹¤."

                    # ìƒì„¸ ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
                    for exit_obj in exits_with_elev[:2]:
                        if hasattr(exit_obj, 'elevator_location') and exit_obj.elevator_location:
                            doc += f" {exit_obj.exit_number}ë²ˆ ì¶œêµ¬ ì—˜ë¦¬ë² ì´í„°ëŠ” {exit_obj.elevator_location}ì— ìˆìŠµë‹ˆë‹¤."

                    documents.append(doc)
                    metadatas.append({
                        "source": "DB",
                        "category": "ì¶œêµ¬",
                        "station": station.name
                    })

                # í¸ì˜ì‹œì„¤ ì •ë³´
                facility = db.query(StationFacility).filter(
                    StationFacility.station_id == station.station_id
                ).first()

                if facility:
                    facilities = []
                    if facility.has_nursing_room:
                        facilities.append("ìˆ˜ìœ ì‹¤")
                    if facility.has_wheelchair_charger:
                        facilities.append("íœ ì²´ì–´ ì¶©ì „ì†Œ")
                    if facility.has_meeting_place:
                        facilities.append("ë§Œë‚¨ì˜ ì¥ì†Œ")

                    if facilities:
                        doc = f"{station.name}ì—ëŠ” {', '.join(facilities)}ì´ ìˆìŠµë‹ˆë‹¤."
                        documents.append(doc)
                        metadatas.append({
                            "source": "DB",
                            "category": "í¸ì˜ì‹œì„¤",
                            "station": station.name
                        })

            db.close()
            logger.info(f"âœ… Loaded station documents from DB")

        except Exception as e:
            logger.error(f"âŒ Failed to load data from DB: {e}")

        # 5. ë¬¸ì„œ ì¶”ê°€
        if documents:
            self.add_documents(documents, metadatas)
            logger.info(f"âœ… Total {len(documents)} documents added to RAG knowledge base")
        else:
            logger.warning("âš ï¸ No documents loaded - RAG knowledge base is empty")

    def refresh_knowledge(self, station_name: str = None):
        """
        íŠ¹ì • ì—­ ë˜ëŠ” ì „ì²´ ì§€ì‹ ìƒˆë¡œê³ ì¹¨
        - ì‹¤ì‹œê°„ API ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
        """
        from app.services.api_service import GeneralSeoulAPI

        documents = []
        metadatas = []

        # ì—˜ë¦¬ë² ì´í„° ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
        elevator_data = GeneralSeoulAPI.get_elevator_status(station_name)

        for elev in elevator_data.get('elevators', []):
            station = elev.get('station_name', '')
            location = elev.get('location', '')
            status = elev.get('status', '')
            floors = elev.get('floors', '')

            if station and location:
                doc = f"{station} {location} ì—˜ë¦¬ë² ì´í„°ëŠ” í˜„ì¬ {status} ìƒíƒœì…ë‹ˆë‹¤."
                if floors:
                    doc += f" ìš´í–‰ êµ¬ê°„: {floors}"

                documents.append(doc)
                metadatas.append({
                    "source": "OpenAPI_Realtime",
                    "category": "ì—˜ë¦¬ë² ì´í„°ìƒíƒœ",
                    "station": station
                })

        if documents:
            self.add_documents(documents, metadatas)
            logger.info(f"âœ… Refreshed {len(documents)} elevator status documents")


# Global RAG service instance
rag_service = RAGService()
